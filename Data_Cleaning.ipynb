{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"},"kernelspec":{"display_name":"Python 3.9.0 64-bit","name":"python390jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"metadata":{"interpreter":{"hash":"ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"}},"orig_nbformat":4,"colab":{"name":"Data_Cleaning.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"nffhxdyWVsMg"},"source":["import pandas as pd\n","from datetime import datetime as dt\n","import datetime as dtp\n","import numpy as np\n","from dateutil.relativedelta import relativedelta   \n","import math\n","import random as rd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzHQL0qVVsMk"},"source":["#create MEV data arrays \n","CPIdata = pd.read_csv('MEV\\CPI.csv', delimiter = ',',parse_dates=['DATE'],index_col=['DATE']) #monthlydata\n","CPIdata.columns = [\"CPI\"]\n","HPIdata = pd.read_csv('MEV\\HPI.csv', delimiter = ',',parse_dates=['DATE'],index_col=['DATE']) # quarterly\n","HPIdata.columns = [\"HPI\"]\n","HPIdata= HPIdata.resample('M').ffill()\n","PIdata = pd.read_csv('MEV\\PINC.csv', delimiter = ',',parse_dates=['DATE'],index_col=['DATE'])# quarterly\n","PIdata.columns = [\"PI\"]\n","PIdata=  PIdata.resample('M').ffill()\n","RGDPdata = pd.read_csv('MEV\\RGDP.csv', delimiter = ',',parse_dates=['DATE'],index_col=['DATE'])# quarterly\n","RGDPdata.columns = [\"RGDP\"]\n","RGDPdata = RGDPdata.resample('M').ffill()\n","UEMPdata = pd.read_csv('MEV\\\\UEMP.csv', delimiter = ',',parse_dates=['DATE'],index_col=['DATE'])# quarterly\n","UEMPdata.columns = [\"UEMP\"]\n","UEMPdata = UEMPdata.resample('M').ffill()\n","\n","#normalize date index \n","CPIdata.index = CPIdata.index.strftime('%m%Y')\n","HPIdata.index = HPIdata.index.strftime('%m%Y')\n","PIdata.index = PIdata.index.strftime('%m%Y')\n","RGDPdata.index = RGDPdata.index.strftime('%m%Y')\n","UEMPdata.index = UEMPdata.index.strftime('%m%Y')\n","#Create Single Dataframe for MEV data\n","MEV = pd.concat([CPIdata,HPIdata,RGDPdata,PIdata,UEMPdata],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvT4F6XZVsMm","outputId":"bcabe1db-583e-442f-b819-98f77dc9fa3e"},"source":["#Dataset reduction :Raw to reduced data\n","#Read in column names and the selected columns : driven by CSV inputs\n","col = pd.read_csv('ColumnsNames.csv', delimiter = ',')\n","sel_col = pd.read_csv('SelectedColumns.csv')\n","dataset = pd.DataFrame()\n","flag_read = 0\n","filename_loc = [\"INPUTS\\\\2008Q4.csv\",\"INPUTS\\\\2008Q3.csv\"]\n","seller = ['Bank Of America, N.A.']\n","prop = ['CA']\n","# ,\"INPUTS\\\\2007Q2.csv\",\"INPUTS\\\\2007Q3.csv\",\"INPUTS\\\\2007Q4.csv\",\"INPUTS\\\\2006Q1.csv\",\"INPUTS\\\\2006Q2.csv\",\"INPUTS\\\\2006Q3.csv\",\"INPUTS\\\\2006Q4.csv\",]\n","#needs to be in loop reading chunks of data and creating hte final data set. \n","for location in filename_loc:\n","    for chunk in pd.read_csv(location,chunksize=100000,index_col=False, header=None, delimiter=\"|\"):\n","        chunk.columns = col['Name']\n","        data = chunk[list(sel_col['Final '])]\n","        # can filter data here : use california \n","        fdata = data.query('`Property State` == @prop')\n","        fdata = fdata.query('`Seller Name` == @seller')\n","        # take a subset of the loan ids in the random sample \n","        if flag_read == 0:\n","            dataset=fdata\n","            #flag_read = 1\n","        else:\n","            dataset= dataset.append(fdata)\n","        flag_read = flag_read + 1\n","        # if flag_read == 10:# only for testing, will remove for actual data\n","        #     break\n","    dataset.to_csv('RedData\\RD_' + location[7:])\n","# dataset.to_csv(\"Final_Dataset.csv\")\n","# convert to nuemric based on inputs in CSV\n","#num_cols = list(sel_col[sel_col['Numeric']==1]['Final '])\n","#dataset[num_cols].apply(pd.to_numeric,errors = 'coerce')\n","\n"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sthakur6\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (40,101,105) have mixed types.Specify dtype option on import or set low_memory=False.\n","  if (await self.run_code(code, result,  async_=asy)):\n","C:\\Users\\sthakur6\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (105) have mixed types.Specify dtype option on import or set low_memory=False.\n","  if (await self.run_code(code, result,  async_=asy)):\n","C:\\Users\\sthakur6\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (40,105) have mixed types.Specify dtype option on import or set low_memory=False.\n","  if (await self.run_code(code, result,  async_=asy)):\n","C:\\Users\\sthakur6\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (40,101) have mixed types.Specify dtype option on import or set low_memory=False.\n","  if (await self.run_code(code, result,  async_=asy)):\n","C:\\Users\\sthakur6\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (101) have mixed types.Specify dtype option on import or set low_memory=False.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}]},{"cell_type":"code","metadata":{"id":"TGbz0nwyVsMo","outputId":"256a6e5c-6550-48c4-d020-adb52de266b1"},"source":["file_list = ['ReducedData/RD_2008Q2.csv','ReducedData/RD_2008Q3.csv','ReducedData/RD_2008Q4.csv','ReducedData/RD_2006Q1.csv','ReducedData/RD_2006Q2.csv']\n","# 'ReducedData/RD_2006Q3.csv','ReducedData/RD_2006Q4.csv','ReducedData/RD_2007Q1.csv','ReducedData/RD_2007Q2.csv','ReducedData/RD_2007Q3.csv','ReducedData/RD_2007Q4.csv','ReducedData/RD_2008Q1.csv','ReducedData/RD_2008Q2.csv','ReducedData/RD_2008Q3.csv','ReducedData/RD_2008Q4.csv','ReducedData/RD_2006Q1.csv','ReducedData/RD_2006Q2.csv']\n","dataset_final = pd.DataFrame()\n","for fl in file_list:\n","    print(fl)\n","    t = pd.read_csv(fl)\n","    t= t.drop('Unnamed: 0',axis = 1)\n","    # print('Debug')\n","\n","    # print(t['Current Loan Delinquency Status'].value_counts())\n","    # take random sample of 40% loan ids\n","    l = t['Loan Identifier'].unique()\n","    smpl = rd.sample(list(l),int(0.6*len(l)))\n","    #t['Sample'] = [1 if i in smpl else np.nan for i in t['Loan Identifier'] ]\n","    t = t.query(\"`Loan Identifier` == @smpl\")\n","    #t = t.dropna(subset=['Sample'])\n","\n","    #debug\n","    print(\"after sampling\")\n","    # print(t.shape)\n","\n","    # Add status to data . OPtimize using dictionaries or apply using function\n","    t['Status'] = [0] *len(t)\n","    def_stat = {}\n","    # print(t['Current Loan Delinquency Status'].value_counts())\n","    t.loc[(t['Current Loan Delinquency Status']=='XX') ,'Zero Balance Code'] = 1\n","    t.loc[(t['Current Loan Delinquency Status']=='XX') ,'Current Loan Delinquency Status'] = -1\n","    t.loc[(t['Current Loan Delinquency Status'].astype('int')>=3) & (t['Current Loan Delinquency Status'].astype('int')<9),'Status'] = 1\n","    t.loc[(t['Current Loan Delinquency Status'].astype('int')>=0) & (t['Current Loan Delinquency Status'].astype('int')<3),'Status'] = 0\n","    t.loc[(t['Current Loan Delinquency Status'].astype('int')>=9) ,'Status'] = 2\n","    t.loc[(t['Zero Balance Code'] == 1) ,'Status'] = -1\n","    # print(t['Status'].value_counts())\n","\n","    # create target status \n","    tar = list(t['Status'][1:len(t)])\n","    tar.append(0)\n","    t['Target'] = tar\n","\n","    # drop rows after default/prepayment : Ananya\n","    remove_list = []\n","    templ = t.iloc[0,0]\n","    flag = 0\n","    for r_index,i in t.iterrows():\n","        if (i['Loan Identifier'] == templ):\n","            if flag == 0:\n","                if (i['Status'] == 2) or (i['Status']==-1):\n","                    flag = 1\n","                    remove_list.append(r_index)\n","                else:\n","                    continue\n","            else:\n","                remove_list.append(r_index)\n","        else:\n","            templ = i['Loan Identifier']\n","            if (i['Status'] == 2) or (i['Status']==-1):\n","                flag = 1\n","            else:\n","                flag = 0\n","\n","    t.drop(remove_list,axis= 0,inplace= True )\n","\n","    #debug\n","    print(\"after drop\")\n","    # print(t.shape)\n","\n","    # Upfill/downfill the missing data in some columns : JACK  \n","    t.fillna(method = 'ffill', inplace = True)\n","\n","\n","    # Add MEV to dataset: SID\n","    #update format for monthly reporting period \n","    t['Monthly Reporting Period'] = [i.strftime(\"%m%Y\") for i in pd.to_datetime(t['Monthly Reporting Period'],format = '%m%Y')]\n","    t['HPI']= [MEV.loc[i,'HPI'] for i in t['Monthly Reporting Period']]\n","    t['CPI']= [MEV.loc[i,'CPI'] for i in t['Monthly Reporting Period']]\n","    t['PI']= [MEV.loc[i,'PI'] for i in t['Monthly Reporting Period']]\n","    t['RGDP']= [MEV.loc[i,'RGDP'] for i in t['Monthly Reporting Period']]\n","    t['UEMP']= [MEV.loc[i,'UEMP'] for i in t['Monthly Reporting Period']]\n","\n","    # output to file \n","    t.to_csv(\"FinalData\\FD_\" +fl[-10:])\n","    dataset_final = dataset_final.append(t)\n","dataset_final.to_csv(\"FinalData.csv\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["ReducedData/RD_2008Q2.csv\n","after sampling\n","after drop\n","ReducedData/RD_2008Q3.csv\n","after sampling\n","after drop\n","ReducedData/RD_2008Q4.csv\n","after sampling\n","after drop\n","ReducedData/RD_2006Q1.csv\n","after sampling\n","after drop\n","ReducedData/RD_2006Q2.csv\n","after sampling\n","after drop\n"]}]}]}